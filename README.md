# Neural-Networks-Assignment-Character-based-language-model-with-Long-Short-Term-Memory
Goal The goal of the assignment is to help you
understand several concepts introduced in the lectures.

Back-propagation: this algorithm allows us
to compute the gradients efficiently in any
(differentiable) neural networks. Here we introduced
the Back-propagation through time
which is the same algorithm applied for recurrent
neural networks.

Recurrent Neural Networks: characterbased
language model is a difficult task, in
general because the network has to remember
very long sequences. The LSTMs, if implemented
correctly will show that it can learn
much better than the Vanilla RNNs.

